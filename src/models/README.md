# RoBERTa Fake News Classifier

Scripts para treinamento e prediÃ§Ã£o de modelo RoBERTa (BERTimbau) para detecÃ§Ã£o de fake news.

## ğŸ“‹ DescriÃ§Ã£o

Este mÃ³dulo implementa um classificador de deep learning usando o modelo BERTimbau (BERT prÃ©-treinado em portuguÃªs) para detectar notÃ­cias falsas no dataset FakeBr News.

## ğŸš€ Scripts DisponÃ­veis

### 1. `train_roberta_classifier.py`

Script principal para treinar o modelo RoBERTa.

**Uso bÃ¡sico:**
```bash
python src/models/train_roberta_classifier.py
```

**ParÃ¢metros disponÃ­veis:**
- `--data-path`: Caminho para o arquivo de dados (padrÃ£o: `data/processed/fakebr_news.parquet`)
- `--model-name`: Nome do modelo prÃ©-treinado (padrÃ£o: `neuralmind/bert-base-portuguese-cased`)
- `--max-length`: Comprimento mÃ¡ximo das sequÃªncias (padrÃ£o: `128`)
- `--batch-size`: Tamanho do batch (padrÃ£o: `8`)
- `--epochs`: NÃºmero de Ã©pocas (padrÃ£o: `3`)
- `--learning-rate`: Taxa de aprendizado (padrÃ£o: `2e-5`)
- `--test-size`: ProporÃ§Ã£o do conjunto de teste (padrÃ£o: `0.2`)
- `--random-state`: Seed para reprodutibilidade (padrÃ£o: `42`)
- `--save-dir`: DiretÃ³rio para salvar modelos e resultados (padrÃ£o: `models`)

**Exemplo com parÃ¢metros customizados:**
```bash
python src/models/train_roberta_classifier.py \
    --data-path data/processed/fakebr_news.parquet \
    --epochs 5 \
    --batch-size 16 \
    --max-length 256 \
    --save-dir models/roberta_v1
```

**SaÃ­das geradas:**
- `roberta_best_model.bin`: Modelo treinado com melhor acurÃ¡cia
- `config.json`: ConfiguraÃ§Ã£o utilizada no treinamento
- `metrics.json`: MÃ©tricas de avaliaÃ§Ã£o final
- `training_history.json`: HistÃ³rico de treinamento (loss e accuracy por Ã©poca)
- `training_history.png`: GrÃ¡ficos de loss e accuracy
- `confusion_matrix.png`: Matriz de confusÃ£o

### 2. `predict_roberta.py`

Script para fazer prediÃ§Ãµes com modelo treinado.

**Uso para texto Ãºnico:**
```bash
python src/models/predict_roberta.py \
    --model-dir models \
    --text "Texto da notÃ­cia para classificar"
```

**Uso para arquivo:**
```bash
python src/models/predict_roberta.py \
    --model-dir models \
    --input-file data/processed/news_to_classify.parquet \
    --text-column preprocessed_text \
    --output-file results/predictions.parquet
```

**ParÃ¢metros disponÃ­veis:**
- `--model-dir`: DiretÃ³rio contendo o modelo treinado (padrÃ£o: `models`)
- `--text`: Texto Ãºnico para classificar
- `--input-file`: Arquivo parquet com textos para classificar
- `--text-column`: Nome da coluna com textos (padrÃ£o: `preprocessed_text`)
- `--output-file`: Arquivo para salvar resultados

## ğŸ“Š Arquitetura do Modelo

- **Base**: BERTimbau (neuralmind/bert-base-portuguese-cased)
- **Tipo**: Sequence Classification
- **Classes**: 2 (True News, Fake News)
- **ParÃ¢metros**: ~109 milhÃµes

## ğŸ”§ TÃ©cnicas Utilizadas

1. **Fine-tuning**: Ajuste fino do modelo prÃ©-treinado
2. **Gradient Clipping**: NormalizaÃ§Ã£o de gradientes (max_norm=1.0)
3. **Learning Rate Scheduling**: Warmup linear
4. **Stratified Split**: DivisÃ£o estratificada mantendo pares de notÃ­cias
5. **Early Stopping**: Salvamento do melhor modelo baseado em acurÃ¡cia de validaÃ§Ã£o

## ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o

O modelo Ã© avaliado usando:
- AcurÃ¡cia
- F1-Score
- Precision
- Recall
- Matriz de ConfusÃ£o
- Classification Report

## ğŸ’¡ Exemplos de Uso

### Treinar modelo bÃ¡sico
```bash
python src/models/train_roberta_classifier.py
```

### Treinar com GPU e mais Ã©pocas
```bash
python src/models/train_roberta_classifier.py \
    --epochs 5 \
    --batch-size 32
```

### Fazer prediÃ§Ã£o em texto
```bash
python src/models/predict_roberta.py \
    --text "Presidente anuncia nova medida econÃ´mica"
```

### Classificar arquivo completo
```bash
python src/models/predict_roberta.py \
    --input-file data/processed/party_news.parquet \
    --output-file results/party_news_classified.parquet
```

## ğŸ“¦ DependÃªncias

```
torch>=2.0.0
transformers>=4.30.0
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
tqdm>=4.65.0
```

## ğŸ¯ Resultados Esperados

Com as configuraÃ§Ãµes padrÃ£o, espera-se:
- AcurÃ¡cia de validaÃ§Ã£o: ~85-95%
- F1-Score: ~0.85-0.95
- Tempo de treinamento: ~2-4 horas (CPU) ou ~30-60 min (GPU)

## ğŸ“ Notas

- O treinamento em CPU pode ser muito lento. Recomenda-se usar GPU se disponÃ­vel.
- O modelo salvo pode ocupar ~400-500 MB de espaÃ§o em disco.
- Para melhores resultados, considere aumentar `max_length` para 256 ou 512.
- Batch size maior requer mais memÃ³ria mas pode acelerar o treinamento.

## ğŸ” Troubleshooting

**Erro de memÃ³ria (CUDA out of memory):**
- Reduza `batch_size` para 4 ou 2
- Reduza `max_length` para 64 ou 128

**Treinamento muito lento:**
- Verifique se estÃ¡ usando GPU: `torch.cuda.is_available()`
- Reduza o tamanho do dataset para testes
- Reduza nÃºmero de Ã©pocas

**Modelo nÃ£o converge:**
- Aumente o nÃºmero de Ã©pocas
- Ajuste a taxa de aprendizado (tente 1e-5 ou 5e-5)
- Verifique se os dados estÃ£o balanceados
