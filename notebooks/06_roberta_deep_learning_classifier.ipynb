{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RoBERTa Deep Learning Fake News Classifier\n",
                "\n",
                "Este notebook implementa um classificador de deep learning usando RoBERTa para detectar notícias falsas usando o dataset FakeBr News.\n",
                "\n",
                "## Objetivo\n",
                "Criar um modelo RoBERTa que classifique notícias como verdadeiras ou falsas baseado no texto pré-processado (`preprocessed_text`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "cuda available: False\n",
                        "torch version: 2.8.0+cpu\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "print(\"cuda available:\", torch.cuda.is_available())\n",
                "print(\"torch version:\", torch.__version__)\n",
                "if torch.cuda.is_available():\n",
                "    print(\"gpu:\", torch.cuda.get_device_name(0))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cpu\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
                "import torch\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
                "from torch.optim import AdamW  # Importar do torch.optim em vez de transformers\n",
                "from tqdm import tqdm\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Configuração de visualização\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (10, 6)\n",
                "\n",
                "# Verificar se GPU está disponível\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Carregamento dos Dados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset shape: (7200, 31)\n",
                        "\n",
                        "Colunas disponíveis: ['id', 'full_text', 'preprocessed_text', 'size_normalized_text', 'author', 'link', 'category', 'publication_date', 'is_fake', 'text_hash', 'created_at', 'updated_at', 'num_tokens', 'num_palavras_sem_pontuacao', 'num_tipos', 'num_links_internos', 'num_palavras_maiuscula', 'num_verbos', 'num_nomes', 'num_adjetivos', 'num_adverbios', 'num_pronomes', 'num_caracteres', 'avg_sent_length', 'avg_word_length', 'pausality', 'emotiveness', 'diversity', 'percentage_spelling_errors', 'publication_date_as_date', 'sequence']\n",
                        "\n",
                        "Distribuição de classes:\n",
                        "is_fake\n",
                        "True     3600\n",
                        "False    3600\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Porcentagem:\n",
                        "is_fake\n",
                        "True     50.0\n",
                        "False    50.0\n",
                        "Name: proportion, dtype: float64\n"
                    ]
                }
            ],
            "source": [
                "# Carregar dados do parquet\n",
                "df = pd.read_parquet('../data/processed/fakebr_news.parquet')\n",
                "\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "print(f\"\\nColunas disponíveis: {df.columns.tolist()}\")\n",
                "print(f\"\\nDistribuição de classes:\")\n",
                "print(df['is_fake'].value_counts())\n",
                "print(f\"\\nPorcentagem:\")\n",
                "print(df['is_fake'].value_counts(normalize=True) * 100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Valores nulos em preprocessed_text: 0\n",
                        "Valores vazios em preprocessed_text: 0\n",
                        "\n",
                        "Dataset após limpeza: (7200, 31)\n"
                    ]
                }
            ],
            "source": [
                "# Verificar dados faltantes no preprocessed_text\n",
                "print(f\"Valores nulos em preprocessed_text: {df['preprocessed_text'].isnull().sum()}\")\n",
                "print(f\"Valores vazios em preprocessed_text: {(df['preprocessed_text'] == '').sum()}\")\n",
                "\n",
                "# Remover linhas com texto vazio ou nulo\n",
                "df_clean = df[df['preprocessed_text'].notna() & (df['preprocessed_text'] != '')].copy()\n",
                "print(f\"\\nDataset após limpeza: {df_clean.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preparação dos Dados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Shape de X: (7200,)\n",
                        "Shape de y: (7200,)\n",
                        "\n",
                        "Distribuição de y:\n",
                        "Fake (1): 3600 (50.00%)\n",
                        "True (0): 3600 (50.00%)\n"
                    ]
                }
            ],
            "source": [
                "# Separar features (X) e target (y)\n",
                "X = df_clean['preprocessed_text'].values\n",
                "y = df_clean['is_fake'].values.astype(int)\n",
                "\n",
                "print(f\"Shape de X: {X.shape}\")\n",
                "print(f\"Shape de y: {y.shape}\")\n",
                "print(f\"\\nDistribuição de y:\")\n",
                "print(f\"Fake (1): {y.sum()} ({y.sum()/len(y)*100:.2f}%)\")\n",
                "print(f\"True (0): {len(y) - y.sum()} ({(len(y) - y.sum())/len(y)*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tamanho do conjunto de treino: 5760\n",
                        "Tamanho do conjunto de teste: 1440\n",
                        "\n",
                        "Distribuição no treino - Fake: 2880, True: 2880\n",
                        "Distribuição no teste - Fake: 720, True: 720\n"
                    ]
                }
            ],
            "source": [
                "# Split estratificado mantendo os pares juntos\n",
                "unique_sequences = df_clean['sequence'].unique()\n",
                "train_sequences, test_sequences = train_test_split(\n",
                "    unique_sequences, \n",
                "    test_size=0.2, \n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "# Criar máscaras para train e test\n",
                "train_mask = df_clean['sequence'].isin(train_sequences)\n",
                "test_mask = df_clean['sequence'].isin(test_sequences)\n",
                "\n",
                "X_train = df_clean[train_mask]['preprocessed_text'].values\n",
                "X_test = df_clean[test_mask]['preprocessed_text'].values\n",
                "y_train = df_clean[train_mask]['is_fake'].values.astype(int)\n",
                "y_test = df_clean[test_mask]['is_fake'].values.astype(int)\n",
                "\n",
                "print(f\"Tamanho do conjunto de treino: {len(X_train)}\")\n",
                "print(f\"Tamanho do conjunto de teste: {len(X_test)}\")\n",
                "print(f\"\\nDistribuição no treino - Fake: {y_train.sum()}, True: {len(y_train) - y_train.sum()}\")\n",
                "print(f\"Distribuição no teste - Fake: {y_test.sum()}, True: {len(y_test) - y_test.sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configuração do RoBERTa\n",
                "\n",
                "Vamos usar o modelo RoBERTa pré-treinado em português (BERTimbau)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tokenizer carregado: neuralmind/bert-base-portuguese-cased\n"
                    ]
                }
            ],
            "source": [
                "# Configurações\n",
                "MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'  # BERTimbau\n",
                "MAX_LENGTH = 128\n",
                "BATCH_SIZE = 8\n",
                "EPOCHS = 3\n",
                "LEARNING_RATE = 2e-5\n",
                "\n",
                "# Carregar tokenizer\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
                "print(f\"Tokenizer carregado: {MODEL_NAME}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Criação do Dataset PyTorch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train batches: 720\n",
                        "Test batches: 180\n"
                    ]
                }
            ],
            "source": [
                "class NewsDataset(Dataset):\n",
                "    def __init__(self, texts, labels, tokenizer, max_length):\n",
                "        self.texts = texts\n",
                "        self.labels = labels\n",
                "        self.tokenizer = tokenizer\n",
                "        self.max_length = max_length\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.texts)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        text = str(self.texts[idx])\n",
                "        label = self.labels[idx]\n",
                "        \n",
                "        encoding = self.tokenizer.encode_plus(\n",
                "            text,\n",
                "            add_special_tokens=True,\n",
                "            max_length=self.max_length,\n",
                "            padding='max_length',\n",
                "            truncation=True,\n",
                "            return_attention_mask=True,\n",
                "            return_tensors='pt'\n",
                "        )\n",
                "        \n",
                "        return {\n",
                "            'input_ids': encoding['input_ids'].flatten(),\n",
                "            'attention_mask': encoding['attention_mask'].flatten(),\n",
                "            'labels': torch.tensor(label, dtype=torch.long)\n",
                "        }\n",
                "\n",
                "# Criar datasets\n",
                "train_dataset = NewsDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
                "test_dataset = NewsDataset(X_test, y_test, tokenizer, MAX_LENGTH)\n",
                "\n",
                "# Criar dataloaders\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
                "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
                "\n",
                "print(f\"Train batches: {len(train_loader)}\")\n",
                "print(f\"Test batches: {len(test_loader)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Criação e Configuração do Modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Modelo carregado: neuralmind/bert-base-portuguese-cased\n",
                        "Total de parâmetros: 108924674\n",
                        "Total de steps de treinamento: 2160\n"
                    ]
                }
            ],
            "source": [
                "# Carregar modelo\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\n",
                "    MODEL_NAME,\n",
                "    num_labels=2\n",
                ")\n",
                "model = model.to(device)\n",
                "\n",
                "# Configurar otimizador\n",
                "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
                "\n",
                "# Configurar scheduler\n",
                "total_steps = len(train_loader) * EPOCHS\n",
                "scheduler = get_linear_schedule_with_warmup(\n",
                "    optimizer,\n",
                "    num_warmup_steps=0,\n",
                "    num_training_steps=total_steps\n",
                ")\n",
                "\n",
                "print(f\"Modelo carregado: {MODEL_NAME}\")\n",
                "print(f\"Total de parâmetros: {sum(p.numel() for p in model.parameters())}\")\n",
                "print(f\"Total de steps de treinamento: {total_steps}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Funções de Treinamento e Avaliação"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
                "    model.train()\n",
                "    losses = []\n",
                "    correct_predictions = 0\n",
                "    \n",
                "    progress_bar = tqdm(data_loader, desc='Training')\n",
                "    \n",
                "    for batch in progress_bar:\n",
                "        input_ids = batch['input_ids'].to(device)\n",
                "        attention_mask = batch['attention_mask'].to(device)\n",
                "        labels = batch['labels'].to(device)\n",
                "        \n",
                "        outputs = model(\n",
                "            input_ids=input_ids,\n",
                "            attention_mask=attention_mask,\n",
                "            labels=labels\n",
                "        )\n",
                "        \n",
                "        loss = outputs.loss\n",
                "        logits = outputs.logits\n",
                "        \n",
                "        _, preds = torch.max(logits, dim=1)\n",
                "        correct_predictions += torch.sum(preds == labels)\n",
                "        losses.append(loss.item())\n",
                "        \n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
                "        optimizer.step()\n",
                "        scheduler.step()\n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        progress_bar.set_postfix({'loss': loss.item()})\n",
                "    \n",
                "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n",
                "\n",
                "def eval_model(model, data_loader, device):\n",
                "    model.eval()\n",
                "    losses = []\n",
                "    correct_predictions = 0\n",
                "    predictions = []\n",
                "    true_labels = []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for batch in tqdm(data_loader, desc='Evaluating'):\n",
                "            input_ids = batch['input_ids'].to(device)\n",
                "            attention_mask = batch['attention_mask'].to(device)\n",
                "            labels = batch['labels'].to(device)\n",
                "            \n",
                "            outputs = model(\n",
                "                input_ids=input_ids,\n",
                "                attention_mask=attention_mask,\n",
                "                labels=labels\n",
                "            )\n",
                "            \n",
                "            loss = outputs.loss\n",
                "            logits = outputs.logits\n",
                "            \n",
                "            _, preds = torch.max(logits, dim=1)\n",
                "            correct_predictions += torch.sum(preds == labels)\n",
                "            losses.append(loss.item())\n",
                "            \n",
                "            predictions.extend(preds.cpu().numpy())\n",
                "            true_labels.extend(labels.cpu().numpy())\n",
                "    \n",
                "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses), predictions, true_labels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Treinamento do Modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Epoch 1/3\n",
                        "--------------------------------------------------\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Training:  15%|█▌        | 111/720 [41:56<3:50:04, 22.67s/it, loss=0.00649]\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m train_acc, train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Train accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     24\u001b[39m val_acc, val_loss, _, _ = eval_model(\n\u001b[32m     25\u001b[39m     model,\n\u001b[32m     26\u001b[39m     test_loader,\n\u001b[32m     27\u001b[39m     device\n\u001b[32m     28\u001b[39m )\n",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, data_loader, optimizer, scheduler, device)\u001b[39m\n\u001b[32m     23\u001b[39m correct_predictions += torch.sum(preds == labels)\n\u001b[32m     24\u001b[39m losses.append(loss.item())\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m     28\u001b[39m optimizer.step()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luksl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luksl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luksl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
                        "\u001b[31mKeyboardInterrupt\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "history = {\n",
                "    'train_acc': [],\n",
                "    'train_loss': [],\n",
                "    'val_acc': [],\n",
                "    'val_loss': []\n",
                "}\n",
                "\n",
                "best_accuracy = 0\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    print(f'\\nEpoch {epoch + 1}/{EPOCHS}')\n",
                "    print('-' * 50)\n",
                "    \n",
                "    train_acc, train_loss = train_epoch(\n",
                "        model,\n",
                "        train_loader,\n",
                "        optimizer,\n",
                "        scheduler,\n",
                "        device\n",
                "    )\n",
                "    \n",
                "    print(f'Train loss: {train_loss:.4f} | Train accuracy: {train_acc:.4f}')\n",
                "    \n",
                "    val_acc, val_loss, _, _ = eval_model(\n",
                "        model,\n",
                "        test_loader,\n",
                "        device\n",
                "    )\n",
                "    \n",
                "    print(f'Val loss: {val_loss:.4f} | Val accuracy: {val_acc:.4f}')\n",
                "    \n",
                "    history['train_acc'].append(train_acc.item())\n",
                "    history['train_loss'].append(train_loss)\n",
                "    history['val_acc'].append(val_acc.item())\n",
                "    history['val_loss'].append(val_loss)\n",
                "    \n",
                "    if val_acc > best_accuracy:\n",
                "        torch.save(model.state_dict(), '../models/roberta_best_model.bin')\n",
                "        best_accuracy = val_acc\n",
                "        print(f'Best model saved with accuracy: {best_accuracy:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Visualização do Treinamento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Loss\n",
                "axes[0].plot(history['train_loss'], label='Train Loss')\n",
                "axes[0].plot(history['val_loss'], label='Val Loss')\n",
                "axes[0].set_title('Perda por Época')\n",
                "axes[0].set_xlabel('Época')\n",
                "axes[0].set_ylabel('Perda')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Accuracy\n",
                "axes[1].plot(history['train_acc'], label='Train Accuracy')\n",
                "axes[1].plot(history['val_acc'], label='Val Accuracy')\n",
                "axes[1].set_title('Acurácia por Época')\n",
                "axes[1].set_xlabel('Época')\n",
                "axes[1].set_ylabel('Acurácia')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Avaliação Final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregar melhor modelo\n",
                "model.load_state_dict(torch.load('../models/roberta_best_model.bin'))\n",
                "\n",
                "# Avaliar no conjunto de teste\n",
                "test_acc, test_loss, y_pred, y_true = eval_model(model, test_loader, device)\n",
                "\n",
                "print(\"\\n=== Resultados Finais ===\")\n",
                "print(f\"Acurácia no teste: {test_acc:.4f}\")\n",
                "print(f\"F1-Score no teste: {f1_score(y_true, y_pred):.4f}\")\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_true, y_pred, target_names=['True News', 'Fake News']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Matriz de Confusão"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Matriz de Confusão\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=['True News', 'Fake News'],\n",
                "            yticklabels=['True News', 'Fake News'])\n",
                "plt.title('Matriz de Confusão - RoBERTa')\n",
                "plt.ylabel('Valor Real')\n",
                "plt.xlabel('Predição')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Calcular métricas da matriz de confusão\n",
                "tn, fp, fn, tp = cm.ravel()\n",
                "print(f\"\\nMétricas da Matriz de Confusão:\")\n",
                "print(f\"True Negatives (TN): {tn}\")\n",
                "print(f\"False Positives (FP): {fp}\")\n",
                "print(f\"False Negatives (FN): {fn}\")\n",
                "print(f\"True Positives (TP): {tp}\")\n",
                "print(f\"\\nPrecisão: {tp/(tp+fp):.4f}\")\n",
                "print(f\"Recall: {tp/(tp+fn):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Teste com Exemplos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_text(text, model, tokenizer, device, max_length=512):\n",
                "    model.eval()\n",
                "    \n",
                "    encoding = tokenizer.encode_plus(\n",
                "        text,\n",
                "        add_special_tokens=True,\n",
                "        max_length=max_length,\n",
                "        padding='max_length',\n",
                "        truncation=True,\n",
                "        return_attention_mask=True,\n",
                "        return_tensors='pt'\n",
                "    )\n",
                "    \n",
                "    input_ids = encoding['input_ids'].to(device)\n",
                "    attention_mask = encoding['attention_mask'].to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
                "        _, prediction = torch.max(outputs.logits, dim=1)\n",
                "    \n",
                "    return \"FAKE\" if prediction.item() == 1 else \"TRUE\"\n",
                "\n",
                "# Testar com alguns exemplos\n",
                "print(\"Exemplos de Predições:\\n\")\n",
                "for i in range(5):\n",
                "    idx = np.random.randint(0, len(X_test))\n",
                "    text = X_test[idx]\n",
                "    real_label = \"FAKE\" if y_test[idx] == 1 else \"TRUE\"\n",
                "    predicted_label = predict_text(text, model, tokenizer, device)\n",
                "    \n",
                "    print(f\"Texto: {text[:100]}...\")\n",
                "    print(f\"Real: {real_label} | Predição: {predicted_label}\")\n",
                "    print(f\"Correto: {'✓' if real_label == predicted_label else '✗'}\")\n",
                "    print(\"-\" * 80)\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Conclusões\n",
                "\n",
                "Este notebook implementou um classificador de deep learning usando RoBERTa (BERTimbau) para detectar notícias falsas.\n",
                "\n",
                "### Principais Resultados:\n",
                "- Utilizamos o modelo BERTimbau pré-treinado em português\n",
                "- O modelo foi fine-tuned no dataset FakeBr News\n",
                "- Implementamos data augmentation através do split estratificado por sequências\n",
                "- Utilizamos técnicas de regularização (gradient clipping, learning rate scheduling)\n",
                "\n",
                "### Vantagens do RoBERTa:\n",
                "- Captura contexto semântico profundo do texto\n",
                "- Pré-treinado em grande corpus de português\n",
                "- Melhor performance em tarefas de classificação de texto\n",
                "\n",
                "### Próximos Passos:\n",
                "1. Experimentar com diferentes modelos (GPT-2, T5, etc.)\n",
                "2. Implementar ensemble com modelos tradicionais (SVM, Naive Bayes)\n",
                "3. Adicionar features adicionais (metadados, features linguísticas)\n",
                "4. Implementar técnicas de interpretabilidade (LIME, SHAP)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
