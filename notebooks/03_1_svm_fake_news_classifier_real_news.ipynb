{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SVM Fake News Classifier - Classificação de Notícias Externas\n",
                "\n",
                "Este notebook utiliza o modelo SVM treinado para classificar notícias da base externa `party_news.parquet`.\n",
                "\n",
                "## Objetivo\n",
                "Carregar o modelo SVM já treinado e aplicá-lo na base de dados externa para detectar possíveis fake news."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import pickle\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Configuração de visualização\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Carregar Modelo e Vetorizador"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregar o modelo SVM treinado\n",
                "with open('../models/svm_fake_news_classifier.pkl', 'rb') as f:\n",
                "    svm_model = pickle.load(f)\n",
                "\n",
                "# Carregar o vetorizador TF-IDF\n",
                "with open('../models/tfidf_vectorizer.pkl', 'rb') as f:\n",
                "    tfidf = pickle.load(f)\n",
                "\n",
                "print(\"Modelo e vetorizador carregados com sucesso!\")\n",
                "print(f\"Tipo do modelo: {type(svm_model)}\")\n",
                "print(f\"Número de features do TF-IDF: {len(tfidf.get_feature_names_out())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Carregar Dados Externos (Party News)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregar dados externos\n",
                "df_external = pd.read_parquet('../data/external/party_news.parquet')\n",
                "\n",
                "print(f\"Shape dos dados externos: {df_external.shape}\")\n",
                "print(f\"\\nColunas disponíveis: {df_external.columns.tolist()}\")\n",
                "print(f\"\\nPrimeiras linhas:\")\n",
                "df_external.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verificar informações sobre os dados\n",
                "print(\"Informações sobre os dados:\")\n",
                "df_external.info()\n",
                "\n",
                "print(\"\\nEstatísticas descritivas:\")\n",
                "df_external.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preparar Dados para Classificação"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verificar se existe coluna de texto pré-processado\n",
                "# Ajustar o nome da coluna conforme necessário\n",
                "text_column = None\n",
                "for col in ['preprocessed_text', 'text', 'content', 'full_text']:\n",
                "    if col in df_external.columns:\n",
                "        text_column = col\n",
                "        break\n",
                "\n",
                "if text_column is None:\n",
                "    raise ValueError(\"Não foi encontrada coluna de texto nos dados!\")\n",
                "\n",
                "print(f\"Usando coluna: {text_column}\")\n",
                "\n",
                "# Remover valores nulos\n",
                "df_clean = df_external[df_external[text_column].notna() & (df_external[text_column] != '')].copy()\n",
                "print(f\"\\nDados após limpeza: {df_clean.shape}\")\n",
                "print(f\"Registros removidos: {len(df_external) - len(df_clean)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Vetorizar Textos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vetorizar os textos usando o TF-IDF já treinado\n",
                "X_external = tfidf.transform(df_clean[text_column].values)\n",
                "\n",
                "print(f\"Shape da matriz TF-IDF: {X_external.shape}\")\n",
                "print(f\"Número de documentos: {X_external.shape[0]}\")\n",
                "print(f\"Número de features: {X_external.shape[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Fazer Predições"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fazer predições\n",
                "predictions = svm_model.predict(X_external)\n",
                "\n",
                "# Adicionar predições ao dataframe\n",
                "df_clean['is_fake_prediction'] = predictions\n",
                "\n",
                "# Contar predições\n",
                "print(\"Distribuição das predições:\")\n",
                "print(df_clean['is_fake_prediction'].value_counts())\n",
                "print(\"\\nPorcentagem:\")\n",
                "print(df_clean['is_fake_prediction'].value_counts(normalize=True) * 100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Análise dos Resultados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizar distribuição das predições\n",
                "plt.figure(figsize=(10, 6))\n",
                "df_clean['is_fake_prediction'].value_counts().plot(kind='bar', color=['green', 'red'])\n",
                "plt.title('Distribuição das Predições - Party News')\n",
                "plt.xlabel('Classificação (0=True, 1=Fake)')\n",
                "plt.ylabel('Quantidade')\n",
                "plt.xticks(rotation=0)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Se existir coluna de partido, analisar por partido\n",
                "party_column = None\n",
                "for col in ['party', 'partido', 'source', 'fonte']:\n",
                "    if col in df_clean.columns:\n",
                "        party_column = col\n",
                "        break\n",
                "\n",
                "if party_column:\n",
                "    print(f\"\\nAnálise por {party_column}:\")\n",
                "    party_analysis = df_clean.groupby(party_column)['is_fake_prediction'].agg(['count', 'sum', 'mean'])\n",
                "    party_analysis.columns = ['Total', 'Fake_Count', 'Fake_Percentage']\n",
                "    party_analysis['Fake_Percentage'] = party_analysis['Fake_Percentage'] * 100\n",
                "    party_analysis = party_analysis.sort_values('Fake_Percentage', ascending=False)\n",
                "    print(party_analysis)\n",
                "    \n",
                "    # Visualizar\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    party_analysis['Fake_Percentage'].plot(kind='bar')\n",
                "    plt.title('Porcentagem de Fake News por Partido/Fonte')\n",
                "    plt.xlabel(party_column.capitalize())\n",
                "    plt.ylabel('% Fake News')\n",
                "    plt.xticks(rotation=45, ha='right')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"Coluna de partido/fonte não encontrada\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Exemplos de Notícias Classificadas como Fake"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mostrar exemplos de notícias classificadas como fake\n",
                "fake_news = df_clean[df_clean['is_fake_prediction'] == 1]\n",
                "\n",
                "print(f\"Total de notícias classificadas como FAKE: {len(fake_news)}\")\n",
                "print(\"\\nExemplos de notícias classificadas como FAKE:\\n\")\n",
                "\n",
                "for idx, row in fake_news.head(10).iterrows():\n",
                "    print(f\"{'='*80}\")\n",
                "    if party_column and party_column in row:\n",
                "        print(f\"Partido/Fonte: {row[party_column]}\")\n",
                "    print(f\"Texto: {row[text_column][:200]}...\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Salvar Resultados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Salvar resultados em um novo arquivo\n",
                "output_path = '../data/processed/party_news_classified.parquet'\n",
                "df_clean.to_parquet(output_path, index=False)\n",
                "print(f\"Resultados salvos em: {output_path}\")\n",
                "\n",
                "# Salvar também um CSV com apenas as fake news\n",
                "fake_news_path = '../data/processed/party_news_fake_only.csv'\n",
                "fake_news.to_csv(fake_news_path, index=False)\n",
                "print(f\"Fake news salvas em: {fake_news_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Resumo Final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"RESUMO DA CLASSIFICAÇÃO\")\n",
                "print(\"=\"*80)\n",
                "print(f\"Total de notícias analisadas: {len(df_clean)}\")\n",
                "print(f\"Notícias classificadas como TRUE: {(df_clean['is_fake_prediction'] == 0).sum()}\")\n",
                "print(f\"Notícias classificadas como FAKE: {(df_clean['is_fake_prediction'] == 1).sum()}\")\n",
                "print(f\"\\nPorcentagem de FAKE news: {(df_clean['is_fake_prediction'].mean() * 100):.2f}%\")\n",
                "print(f\"Porcentagem de TRUE news: {((1 - df_clean['is_fake_prediction'].mean()) * 100):.2f}%\")\n",
                "print(\"=\"*80)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
